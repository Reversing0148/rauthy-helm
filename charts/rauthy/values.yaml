# Default values for rauthy.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
# Setting a replica count of higher than 1 will enable clustered mode for rauthy.
# Odd numbers are enforced to ensure raft consensus can be achieved.
replicaCount: 1

# This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
image:
  repository: ghcr.io/sebadob/rauthy
  # This sets the pull policy for images.
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

# This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []

# Configuration for the update strategy of the StatefulSet more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 0

# This is for setting Kubernetes Annotations to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
podAnnotations: {}
# This is for setting Kubernetes Labels to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
podLabels: {}

podSecurityContext:
  runAsNonRoot: true
  fsGroup: 10001
  seccompProfile:
    type: RuntimeDefault

securityContext:
  capabilities:
    drop:
      - ALL
  runAsUser: 10001
  runAsGroup: 10001
  runAsNonRoot: true
  allowPrivilegeEscalation: false
  seccompProfile:
    type: RuntimeDefault


# This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
service:
  # Additional annotations on the service resource.
  annotations: {}
  # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
  type: ClusterIP
  # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
  port: 8080
  # Indicate the scheme used by the Rauthy server. Eg.: "http" or "https"
  scheme: "http"

# This is for setting up a headless service to enable pod-to-pod communication for clustered workloads
# The headless service is only created when replicaCount is greater than 1
headlessService:
  ports:
    raft: 8100
    api: 8200

# This will enable the metrics in the generated config.toml
# if config.generate is true and will expose the metrics port in the service.
metrics:
  enabled: false
  port: 9090

# This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #   - secretName: rauthy-ingress-tls
  #     hosts:
  #       - chart-example.local

# -- Expose the service via gateway-api HTTPRoute
# Requires Gateway API resources and suitable controller installed within the cluster
# (see: https://gateway-api.sigs.k8s.io/guides/)
httpRoute:
  # HTTPRoute enabled.
  enabled: false
  # HTTPRoute annotations.
  annotations: {}
  # Which Gateways this Route is attached to.
  parentRefs:
  - name: gateway
    sectionName: http
    # namespace: default
  # Hostnames matching HTTP header.
  hostnames:
  - chart-example.local
  # List of rules and filters applied.
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /headers
  #   filters:
  #   - type: RequestHeaderModifier
  #     requestHeaderModifier:
  #       set:
  #       - name: My-Overwrite-Header
  #         value: this-is-the-only-value
  #       remove:
  #       - User-Agent
  # - matches:
  #   - path:
  #       type: PathPrefix
  #       value: /echo
  #     headers:
  #     - name: version
  #       value: v2

# This is for configuring resource requests and limits for the rauthy container.
# To ensure Rauthy is scheduled properly please configure the memory requests accordingly.
# Make sure there is at least (MAX_HASH_THREADS * ARGON2_M_COST / 1024) + idle memory available.
# The default Rauthy configuration requires at least 256Mi of memory for hashing on top
# of the idle memory of the container (around 100Mi using hiqlite).
# Read more at https://sebadob.github.io/rauthy/config/tuning.html#password-hashing
resources:
  requests:
    cpu: 100m
    memory: 360Mi
  # Setting limits for Rauthy is overall not recommended nor required. However you might find it best
  # to set limits in certain environments. Setting a cpu limit can help to avoid noisy neighbor situations
  # on the node should Rauthy experience high load. Since Rust is not a garbage collected language you don't
  # really need to set memory limits. Instead make sure to keep the memory requests updated.
  # limits:
  #   cpu: 200m
  #   memory: 400Mi

# Rauthy uses jemalloc as memory allocator which you can tune via an environment variable.
# By default uses the medium instance with up to 500-1000 users.
# To get the best performance it is recommended to use the preset based on your usercount.
# small: up to 500 users, medium: up to 1000 users, big: 1000+ users, open: up to millions of users
# Read more at: https://sebadob.github.io/rauthy/config/tuning.html#memory-allocator
malloc:
  # Preset options are: small, medium, big, open and custom
  preset: medium
  # Custom options when preset is set to "custom"
  custom: ""

# This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  httpGet:
    path: /auth/v1/health
    port: http
  initialDelaySeconds: 1
  periodSeconds: 30
readinessProbe:
  httpGet:
    path: /ping
    port: api
  initialDelaySeconds: 5
  periodSeconds: 1

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

# By default podAntiAffinity using topologyKey: kubernetes.io/hostname is preferred with weight 100
affinity: {}

topologySpreadConstraints: []

# This allows for mounting config.toml. It is in your own interest, to set
# a secret that is not managed by helm so that you can retain your configuration
# and keys across redeployments.
# Either externalSecret or config can be used but not both.
externalSecret: ""

# This allows for automatic generation of config.toml based on values
# in this values.yaml file. The generated config is enough to get you
# started with rauthy.
# Either externalSecret or config can be used but not both.
config:
  generate: true
  # Set proxy_mode and respective trusted_proxies for the generated config.toml
  # To get the cidr range of your kubernetes cluster use the following:
  # kubectl cluster-info dump | grep -m 1 "cluster-cidr"
  # Multiple trusted proxies can be set using an array.
  trustedProxies: []
  #  - "10.62.0.0/24"
  #  - "172.16.0.0/12"


# Extra environment variables to pass to the container.
# This is mostly for backwards compatibility. New installations should
# prefer using the config.toml via the externalSecret option.
env: []
# - name: FOO
#   value: "BAR"

# Persistence configuration for the volumeClaimTemplate.
# Emptydir will be used if disabled
persistence:
  enabled: false
  size: 128Mi
  accessMode: ReadWriteOnce
  storageClassName: ""

# Configuration for enabling and customizing the ServiceMonitor resource.
# This is used to integrate with Prometheus for monitoring purposes.
serviceMonitor:
  # Enable or disable the ServiceMonitor resource.
  enabled: false
  # Namespace override for the ServiceMonitor resource.
  namespaceOverride: ""
  # The port exposed by the service to scrape metrics from.
  port: metrics
  # The interval at which Prometheus will scrape metrics.
  interval: 30s
